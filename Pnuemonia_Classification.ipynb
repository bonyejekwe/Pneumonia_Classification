{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torchvision import io, transforms\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9c9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT, IMAGE_LENGTH = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b85f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset: list):\n",
    "    \"\"\"dataset: 'train', 'val', or 'test'. Read in and return list of image\n",
    "    tensors (X) and list of int labels (y)\"\"\"\n",
    "    label = {\"normal\": 0, \"pneumonia\": 1}\n",
    "    upper = {\"normal\": \"NORMAL\", \"pneumonia\": \"PNEUMONIA\"}\n",
    "    \n",
    "    rows = []\n",
    "    for clf in label.keys(): # for each label (normal and pneumonia)\n",
    "        with open(f\"chest_xray/{clf}_{dataset}.txt\") as file:  # read in names \n",
    "            for line in file.readlines():\n",
    "                image_name = line.strip()  # remove '\\n' at end of string\n",
    "                image = io.read_image(f\"chest_xray/{dataset}/{upper[clf]}/{image_name}\") # tensor\n",
    "                # ex: \"chest_xray/test/NORMAL/image_name.txt\"\n",
    "                if image.shape[0] == 1:  # some images have three dimensions\n",
    "                    rows.append([image, label[clf]])\n",
    "\n",
    "    random.shuffle(rows)\n",
    "    images, labels = [e[0] for e in rows], [e[1] for e in rows]  # split into X and y\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d64b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_data(\"train\")\n",
    "X_val, y_val = read_data(\"val\")\n",
    "X_test, y_test = read_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da93180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = [transforms.Resize([IMAGE_HEIGHT, IMAGE_LENGTH])(X_train[i]) for i in range(len(X_train))]\n",
    "X_train_new = torch.stack(X_train_new)\n",
    "\n",
    "X_val_new = [transforms.Resize([IMAGE_HEIGHT, IMAGE_LENGTH])(X_val[i]) for i in range(len(X_val))]\n",
    "X_val_new = torch.stack(X_val_new)\n",
    "\n",
    "X_test_new = [transforms.Resize([IMAGE_HEIGHT, IMAGE_LENGTH])(X_test[i]) for i in range(len(X_test))]\n",
    "X_test_new = torch.stack(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8b1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_new / 255, torch.tensor(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_new / 255, torch.tensor(y_test))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6006048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]              60\n",
      "            Conv2d-2           [-1, 12, 10, 10]           1,812\n",
      "         AvgPool2d-3             [-1, 12, 5, 5]               0\n",
      "              ReLU-4             [-1, 12, 5, 5]               0\n",
      "            Conv2d-5            [-1, 128, 1, 1]          38,528\n",
      "              ReLU-6            [-1, 128, 1, 1]               0\n",
      "            Linear-7                   [-1, 64]           8,256\n",
      "              ReLU-8                   [-1, 64]               0\n",
      "            Linear-9                    [-1, 1]              65\n",
      "          Sigmoid-10                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 48,721\n",
      "Trainable params: 48,721\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 0.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_size = 1 * IMAGE_HEIGHT * IMAGE_LENGTH  # input spatial dimension of images\n",
    "hidden_size = 256 #128         # width of hidden layer\n",
    "output_size = 1          # number of output neurons\n",
    "\n",
    "class PneumoniaClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.c1 = torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=3,stride=1,padding=1)\n",
    "        self.c2 = torch.nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5,stride=3,padding=2)\n",
    "        self.c3 = torch.nn.Conv2d(in_channels=12,out_channels=128,kernel_size=5,stride=1,padding=0)\n",
    "        self.max_pool = torch.nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=128,out_features=64)\n",
    "        self.fc2 = torch.nn.Linear(in_features=64,out_features=output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "     \n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.relu(self.max_pool(x))\n",
    "        x = self.relu(self.c3(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        y = self.fc2(x)\n",
    "        y_output = self.sigmoid(y)\n",
    "        return y_output.T[0]\n",
    "\n",
    "model = PneumoniaClassifier().to(DEVICE)\n",
    "summary(model, input_size=(1, IMAGE_HEIGHT, IMAGE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b16af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, device, optimizer, log_interval, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    counter = []\n",
    "    \n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "        img, label = img.float().to(device), label.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = torch.nn.BCELoss()(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Record training loss every log_interval and keep counter of total training images seen\n",
    "        if (i+1) % log_interval == 0:\n",
    "            losses.append(loss.item())\n",
    "            counter.append(\n",
    "                (i * batch_size) + img.size(0) + epoch * len(train_loader.dataset))\n",
    "\n",
    "    return losses, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99174bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(test_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(test_loader):\n",
    "            output = model(img)\n",
    "            pred = torch.round(output)  # round probability into binary classification\n",
    "            tp += sum([1 for pred, true in zip(pred, label) if pred == true and true == 1])\n",
    "            fn += sum([1 for pred, true in zip(pred, label) if pred != true and pred == 0])\n",
    "            fp += sum([1 for pred, true in zip(pred, label) if pred != true and pred == 1])\n",
    "            num_correct += pred.eq(label).sum().item()\n",
    "            test_loss /= len(test_loader)\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, num_correct, tp, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0eecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff574bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 25/25 [01:23<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.05\n",
    "max_epochs=25\n",
    "gamma = 0.95\n",
    "\n",
    "# Recording data\n",
    "log_interval = 1\n",
    "\n",
    "# Instantiate optimizer (model was created in previous cell)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_correct = []\n",
    "for epoch in trange(max_epochs, leave=True, desc='Epochs'):\n",
    "    train_loss, counter = train_one_epoch(train_loader, model, DEVICE, optimizer, log_interval, epoch)\n",
    "    test_loss, num_correct, tp, fn, fp = test_one_epoch(test_loader, model, DEVICE)\n",
    "\n",
    "    # Record results\n",
    "    train_losses.extend(train_loss)\n",
    "    train_counter.extend(counter)\n",
    "    test_losses.append(test_loss)\n",
    "    test_correct.append(num_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6d1bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7223264540337712\n",
      "Recall: 0.9871794871794872\n",
      "F1 Score: 0.8342361863488624\n",
      "Test accuracy: 0.7548076923076923\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {tp/ (tp + fp)}\")\n",
    "print(f\"Recall: {tp/ (tp + fn)}\")\n",
    "print(f\"F1 Score: {tp/( tp + .5*(fp + fn))}\")\n",
    "print(f\"Test accuracy: {test_correct[-1]/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b08d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_resize(rand_idx):\n",
    "    \"\"\"Show the image resize using global variables for height / weight\"\"\"\n",
    "    plt.imshow(X_train[rand_idx][0])\n",
    "    plt.show()\n",
    "#    plt.imshow(transforms.Resize([IMAGE_HEIGHT, IMAGE_LENGTH])(X_train[rand_idx])[0])\n",
    "    plt.imshow(transforms.Resize([28, 28])(X_train[rand_idx])[0])\n",
    "    \n",
    "#show_image_resize(74)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
