{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "IMAGE_HEIGHT, IMAGE_LENGTH = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Feedforward Neural Network (change hidden size to 64, 128, or 256)\n",
    "\n",
    "input_size = 1 * IMAGE_HEIGHT * IMAGE_LENGTH  # input spatial dimension of images\n",
    "hidden_size = 256 #128         # width of hidden layer\n",
    "output_size = 2          # number of output neurons\n",
    "\n",
    "class PneumoniaClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1)\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "     \n",
    "    def forward(self, x):\n",
    "        # Input image is of shape [batch_size, 1, IMAGE_, 28]\n",
    "        x = self.flatten(x)  # Need to flatten to [batch_size, 784] before feeding to fc1\n",
    "        y = self.fc1(x.float())\n",
    "        y = self.act(y)\n",
    "        y = self.fc2(y)\n",
    "        y_output = self.sigmoid(y)\n",
    "        return y_output.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Convolutional Neural Network (different set of convolutional layers)\n",
    "# also can change values for number of channels for each convolutional layer\n",
    "\n",
    "input_size = 1 * IMAGE_HEIGHT * IMAGE_LENGTH  # input spatial dimension of images\n",
    "hidden_size = 256 #128         # width of hidden layer\n",
    "output_size = 2          # number of output neurons\n",
    "\n",
    "class PneumoniaClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.c1 = torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,stride=1,padding=2)\n",
    "        self.c2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1,padding=0)\n",
    "        self.c3 = torch.nn.Conv2d(in_channels=16,out_channels=120,kernel_size=5,stride=1,padding=0)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=120,out_features=84)\n",
    "        self.fc2 = torch.nn.Linear(in_features=84,out_features=output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "     \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pool(x))\n",
    "        x = self.c1(x)\n",
    "        x = self.relu(self.max_pool(x))\n",
    "        x = self.c2(x)\n",
    "        x = self.relu(self.max_pool(x))\n",
    "        x = self.relu(self.c3(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        y_output = self.sigmoid(y)\n",
    "        return y_output.T[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sharpen = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "gaussian_blur = np.array([ [0.0625, 0.125, 0.0625], [0.125,  0.25,  0.125], [0.0625, 0.125, 0.0625]])\n",
    "edge_detection = np.array([[-1, -1, -1], [-1,  8, -1], [-1, -1, -1]])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
